# ğŸ§  Conversational Bot

Private, local, lowâ€‘latency voice assistant with hotword detection, ASR, **streaming LLM â†’ streaming TTS**, bargeâ€‘in, and a tidy `/vitals` dashboard.

---

## âœ¨ Whatâ€™s implemented (and how)

* **Wake word with safe fallback** â€” Porcupine hotword; if itâ€™s missing or fails, the app switches to **textâ€‘based wake matching** without crashing.
* **ASR with clean endpointing** â€” Fasterâ€‘Whisper tuned for short turns; **standby** listens in tight windows; **active sessions** autoâ€‘detect RO/EN (standby favors EN for reliable hotwords).
* **Streaming LLM â†’ streaming TTS** â€” Realâ€‘time token streaming to speech; **timeâ€‘toâ€‘firstâ€‘token (TTFT)** is measured so replies feel snappy.
* **Audio hygiene** â€” System echoâ€‘cancel (AEC), noise suppression, highâ€‘pass filter; **AGC off** to avoid noise pumping & false VAD triggers.
* **No accidental â€œpaâ€¦â€ exits** â€” Session closes **only** on exact goodbyes (e.g., â€œok byeâ€, â€œgataâ€, â€œla revedereâ€).
* **Observability** â€” Prometheus counters + a simple `/vitals` page for roundâ€‘trip, ASR, TTFT, sessions, turns, errors.
* **Double buffer for seamless TTS** â€” Prevents microâ€‘pauses when the bot speaks; while buffer A plays, buffer B synthesizes the next chunk, then they alternate continuously.
* **English <> Romanian** â€” Improved command & QA flow in English while keeping full Romanian support.
* **Honest fallback** â€” If the bot doesnâ€™t know, it says so (â€œIâ€™m not sure about that yet, but I can look it up if youâ€™d like.â€).

---

## ğŸ”§ Practical setup for users (do this)

1. **Select the echoâ€‘cancelled mic**
   Use the `ec_mic` input (see Linux commands below). This is critical so the bot doesnâ€™t hear its own TTS as user speech.

2. **Tune thresholds for your room**

* `min_speech_duration`: **1.0â€“1.2s** (utterances shorter than this are ignored)
* `silence_to_end`: **1200â€“1500 ms** (only for *active* session end, not standby)
* Keep **AGC off** in the OS/driver and inside AEC if exposed.

3. **Keys & env**

* Put API keys in `.env`.
* **Note:** Activating a venv does **not** read `.env` automatically. Either:

  * use `python-dotenv` inside the app, or
  * `export $(grep -v '^#' .env | xargs)` in your shell before `python -m src.app`.

4. **Run with structured logs**

```bash
LOG_LEVEL=INFO LOG_DIR=logs python -m src.app
```

5. **(Optional) Hotword**
   Have a **Picovoice (Porcupine) key** for instant wake (â€œhello robotâ€). Without it, the fallback text matcher still works, just a bit less robust/lowâ€‘latency.

---

## ğŸ§© Mini flow (pipeline)

**Standby & Wake** â†’ (Porcupine **or** text fallback)
â†’ **Acknowledgement** (â€œYes, Iâ€™m listening.â€ / â€œDa, te ascult.â€)
â†’ **Record & endpoint** (VAD on silence; AEC + NS + HPF; AGC off)
â†’ **ASR** (Fasterâ€‘Whisper; session auto RO/EN; standby favors EN)
â†’ **LLM** (streamed generation; **strictâ€‘facts** mode to reduce hallucinations)
â†’ **TTS** (streamed **sentence chunks**)
â†’ **Double buffer** (A plays while B synthesizes; swap)
â†’ **Bargeâ€‘in** (if the user speaks, TTS stops; return to listening)
â†’ **Session end** (idle timeout **or** exactâ€‘match goodbye)

---

## ğŸ™ï¸ Audio Architecture (AEC explained)

**Goal:** prevent the botâ€™s own TTS from being misâ€‘detected as user speech.

**How:** WebRTC AEC uses an **adaptive filter** that estimates the **echo path** (the transformation from farâ€‘end signal â†’ what the mic would hear). With the **farâ€‘end** signal (what we send to speakers) and the **nearâ€‘end** mic input, it continuously **predicts and subtracts** the echo component from the mic stream. This is *not* a static â€œroom fingerprintâ€; it adapts in real time as the environment changes.

Extra guards we use:

* **Exactâ€‘match goodbye only** (no partial â€œpaâ€¦â€ exits).
* **Audio similarity veto**: if incoming mic frames highly correlate with the last TTS frames, ignore them.
* **Voiceâ€‘only gating**: prioritize voiced segments for bargeâ€‘in (reduces knocks/claps).

---

## ğŸ§ª Biggest build obstacles (and fixes)

* **Echo loop (bot hears itself)** â†’ solved with **systemâ€‘level AEC** and selecting `ec_mic`, AGC off, plus TTSâ€‘similarity veto.
* **False exits on â€œpaâ€¦â€** â†’ fixed via **exactâ€‘match goodbyes** only.
* **TTS microâ€‘pauses** â†’ fixed with **double buffering** (A plays while B synthesizes next chunk).
* **Noiseâ€‘triggered bargeâ€‘in** â†’ improved by requiring **voiced segments** and raising the minimum speech duration.

> **BIGGEST OBSTACLE â€” reliable bargeâ€‘in**: now solid with **Cobra VAD**. It also works *without* Picovoice (using WebRTC VAD + thresholds), but Cobra is more robust.

---

## ğŸ§° Linux audio: create echoâ€‘cancel devices (PulseAudio / PipeWire)

> Many modern distros run **PipeWire** with a PulseAudio compatibility layer. The commands below work in both setups if the PulseAudio modules are available.

```bash
# 1) Show current default sink/source
pactl info | sed -n -e 's/^Default Sink: /Default Sink: /p' -e 's/^Default Source: /Default Source: /p'

# 2) Unload any old echo-cancel (ignore errors if not loaded)
pactl unload-module module-echo-cancel 2>/dev/null || true

# 3) Load WebRTC echo-cancel on defaults
DEFAULT_SINK="$(pactl info | awk -F': ' '/Default Sink/{print $2}')"
DEFAULT_SOURCE="$(pactl info | awk -F': ' '/Default Source/{print $2}')"

pactl load-module module-echo-cancel \
  aec_method=webrtc \
  aec_args="analog_gain_control=0 digital_gain_control=0" \
  use_master_format=1 \
  sink_master="$DEFAULT_SINK" \
  source_master="$DEFAULT_SOURCE" \
  sink_name=ec_speaker \
  source_name=ec_mic

# 4) Make the echo-cancelled mic default
pactl set-default-source ec_mic

# 5) Verify
pactl list short sources | grep -Ei 'ec_mic|echo|cancel'
```

## ğŸ”„ Models & reasoning

* **ASR**: Started with OpenAI Whisper, switched to **Fasterâ€‘Whisper** for lower latency on CPU.
* **LLM**: Started on **Llama** (strong bilingual allâ€‘rounder), then tested **Qwenâ€‘2.5 3B Instruct**. Keep a small, fast model for latency; pick based on your device.
* **TTS**: Prefer **Piper** (fast, local). Fallback to `pyttsx3` if needed.
* **Containerization**: Packaging everything in a container can give a **big reliability boost** (consistent deps, easy startup scripts), but is optional.
* **â€œTeaser while thinkingâ€**: Considered a twoâ€‘brain approach (quick TL;DR line while the full answer loads). Dropped due to complexity vs. small latency benefit (most hard questions fit in ~3s extra).

---

## ğŸ—œï¸ Bargeâ€‘in reliability (with and without Picovoice)

* **Works without Picovoice**: WebRTC VAD + tuned thresholds can pause TTS when a *human voice* is detected.
* **Better with Picovoice**: **Cobra VAD** is more robust to noise; **Porcupine** gives instant â€œhello robotâ€ wake.
* If you donâ€™t have keys, the app falls back to text matching for wake and to WebRTC VAD for bargeâ€‘in.

**Proâ€‘tips**

* Raise `min_speech_duration` to avoid coughs/knocks.
* Use voicedâ€‘only gating for bargeâ€‘in.
* Always select the **`ec_mic`** input.

---

## ğŸ§  LLM prompt (edit to your goals)

Update `configs/llm.yaml` to reflect your assistantâ€™s role. Example fields worth tuning:

* **system**: persona, safety rails, bilingual tone
* **tools**: what the model may call
* **style**: concise vs. exploratory
* **facts mode**: stricter for correctness

---

## ğŸ› ï¸ Commands recap

* **Run app with logs**

```bash
LOG_LEVEL=INFO LOG_DIR=logs python -m src.app

```

* **Load simple AEC setup** (see full commands above)
* **Set default mic to `ec_mic`**
* **Verify**: `pactl list short sources | grep -Ei 'ec_mic|echo|cancel'`

---

## ğŸ”œ Toâ€‘do (next iterations)

* **Instant feedback while thinking** â€” quick filler like â€œThanks â€” give me a secâ€¦â€ if the first token is slow, then continue streaming the real answer.
* **Model bakeâ€‘off** â€” compare **Phiâ€‘3 Mini (3.8B)** vs **Qwenâ€‘2.5 (3B)** vs current **Llama**; choose based on latency, fluency, and bilingual accuracy.

---

## ğŸ“¸ Vitals & diagram placeholders

![TTS AEC Schema](src/utils/tts_schema.png)

![Robot Vitals](src/utils/vitals.png)
